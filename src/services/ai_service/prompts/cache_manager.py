"""
Cache Manager for Tool Documentation.

Manages Gemini cache invalidation based on tool YAML changes.
Uses Redis distributed lock to ensure only one pod regenerates cache.
"""

import asyncio
from src.utils.logging import setup_logger
from src.utils.redis_client import redis_client
from src.services.ai_service.prompts.granular_tooling_capabilities import get_tool_docs_hash

logger = setup_logger(__name__)

TOOL_DOCS_HASH_KEY = "praxos:tool_docs_hash"
CACHE_REGENERATION_LOCK_KEY = "praxos:cache_regeneration_lock"
LOCK_TIMEOUT = 120  # 2 minutes


async def check_and_regenerate_cache_if_needed():
    """
    Check if tool documentation has changed and regenerate Gemini cache if needed.
    Uses distributed lock to ensure only one pod regenerates.

    Returns:
        bool: True if cache was regenerated, False otherwise
    """
    try:
        # Get current hash from YAML
        current_hash = get_tool_docs_hash()
        logger.info(f"Current tool docs hash: {current_hash}")

        # Get stored hash from Redis
        stored_hash = await redis_client.get(TOOL_DOCS_HASH_KEY)

        if stored_hash and stored_hash.decode() == current_hash:
            logger.info("Tool docs hash unchanged, cache is up to date")
            return False

        logger.info(f"Tool docs hash changed: {stored_hash} -> {current_hash}")
        logger.info("Attempting to acquire cache regeneration lock...")

        # Try to acquire distributed lock
        lock_acquired = await redis_client.set(
            CACHE_REGENERATION_LOCK_KEY,
            current_hash,
            nx=True,  # Only set if not exists
            ex=LOCK_TIMEOUT  # Expire after timeout
        )

        if not lock_acquired:
            logger.info("Another pod is already regenerating cache, waiting...")

            # Wait for other pod to finish (poll for hash update)
            for i in range(30):  # Wait up to 60 seconds
                await asyncio.sleep(2)
                updated_hash = await redis_client.get(TOOL_DOCS_HASH_KEY)
                if updated_hash and updated_hash.decode() == current_hash:
                    logger.info("Cache regenerated by another pod")
                    return False

            logger.warning("Timeout waiting for cache regeneration by another pod")
            return False

        try:
            logger.info("Lock acquired, regenerating Gemini cache...")

            # Import cache regeneration function
            from src.services.ai_service.prompts import caches

            # TODO: Implement actual cache regeneration
            # new_cache_id = await caches.regenerate_planning_cache()
            # logger.info(f"New cache ID: {new_cache_id}")

            # For now, just log
            logger.info("Cache regeneration not yet implemented")

            # Update stored hash in Redis
            await redis_client.set(TOOL_DOCS_HASH_KEY, current_hash)
            logger.info(f"Updated tool docs hash in Redis: {current_hash}")

            return True

        finally:
            # Release lock
            await redis_client.delete(CACHE_REGENERATION_LOCK_KEY)
            logger.info("Released cache regeneration lock")

    except Exception as e:
        logger.error(f"Error in cache check/regeneration: {e}", exc_info=True)
        return False


async def get_current_tool_docs_version() -> str:
    """
    Get the current tool documentation version hash.

    Returns:
        str: Version hash or 'unknown'
    """
    try:
        stored_hash = await redis_client.get(TOOL_DOCS_HASH_KEY)
        return stored_hash.decode() if stored_hash else get_tool_docs_hash()
    except Exception as e:
        logger.error(f"Error getting tool docs version: {e}")
        return "unknown"
